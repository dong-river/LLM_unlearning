{
    "mode": "unlearn",
    "tokenizer_name_or_path": "EleutherAI/gpt-neo-125m",
    "wandb_project": "Knowledge Unlearning",
    "wandb_run_name": "example",
    "num_train_epochs": 20,
    "check_val_every_n_epoch": 1,
    "check_validation_only": false,
    "do_init_eval": true,
    "train_set": "data/main/lm_extraction_32_0.csv",
    "valid_sets": [
        "data/main/lm_extraction_32_0.csv",
        "data/benchmark/lambada.csv",
        "piqa",
        "ai2_arc",
        "ai2_arc",
        "super_glue",
        "winogrande",
        "data/benchmark/pubmed_qa.csv",
        "hellaswag"
    ],
    "valid_subset_path": [
        "",
        "",
        "",
        "ARC-Easy",
        "ARC-Challenge",
        "copa",
        "winogrande_s",
        "",
        ""
    ],
    "valid_type_path": [
        "target",
        "test",
        "validation",
        "validation",
        "validation",
        "validation",
        "validation",
        "",
        "validation"
    ],
    "train_batch_size": 8,
    "eval_batch_size": 8,
    "gradient_accumulation_steps": 4,
    "ngpu": 1,
    "learning_rate": 5e-5,
    "model_name_or_path": "EleutherAI/gpt-neo-125m",
    "el_threshold": 0.0499,
    "ma_threshold": 0.2994,
    "input_length": 512,
    "output_length": 512,
    "target_length": 200,
    "num_workers": 64,
    "strategy": "deepspeed_stage_2_offload",
    "fp16": true,
    "wandb_log": true
}
